# -*- coding: utf-8 -*-
"""Project2_Happyness_report.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Y9ZjrPHfcE3gvQBg1Gb6KxYCtBKXq3P6
"""

#Imports
import pandas as pd
import numpy as np
from xgboost import XGBRegressor
import xgboost as xgb
from sklearn.preprocessing import OneHotEncoder
from sklearn.metrics import confusion_matrix, accuracy_score, classification_report
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import train_test_split

"""# Data Cleaning
 1. Load happiness score data from year 2015 to 2021
 2. Clean the data to be the same format for all dataset
 3. Concatinate data into one dataframe
"""

# Load data from year 2015 to 2022 individually
from google.colab import files
uploaded = files.upload()

# Create dataframe from year 2015 to 2021
happiness_2015_df = pd.read_csv('2015.csv')
happiness_2016_df = pd.read_csv('2016.csv')
happiness_2017_df = pd.read_csv('2017.csv')
happiness_2018_df = pd.read_csv('2018.csv')
happiness_2019_df = pd.read_csv('2019.csv')
happiness_2020_df = pd.read_csv('2020.csv')
happiness_2021_df = pd.read_csv('2021.csv')
happiness_2022_df = pd.read_csv('2022.csv')

# Add column 'year' to each dataframe
happiness_2015_df['year'] = 2015
happiness_2016_df['year'] = 2016
happiness_2017_df['year'] = 2017
happiness_2018_df['year'] = 2018
happiness_2019_df['year'] = 2019
happiness_2020_df['year'] = 2020
happiness_2021_df['year'] = 2021
happiness_2022_df['year'] = 2022

# Check all dataframes
display(happiness_2015_df.head(2))
display(happiness_2016_df.head(2))
display(happiness_2017_df.head(2))
display(happiness_2018_df.head(2))
display(happiness_2019_df.head(2))
display(happiness_2020_df.head(2))
display(happiness_2021_df.head(2))
display(happiness_2022_df.head(2))

# Data cleaning
# === Year 2015 ===
# Drop columns
happiness_2015_df = happiness_2015_df.drop(['Region','Standard Error','Dystopia Residual','Family'],axis=1)

# Rename column name
happiness_2015_df = happiness_2015_df.rename(columns={'Country':'Country name' ,'Happiness Rank': 'RANK', 'Happiness Score':'Happiness score','Economy (GDP per Capita)':'GDP per capita','Trust (Government Corruption)':'Perceptions of corruption',
                                                      'Health (Life Expectancy)':'Healthy life expectancy'})

# === Year 2016 ===
# Drop columns
happiness_2016_df = happiness_2016_df.drop(['Region','Lower Confidence Interval','Upper Confidence Interval','Dystopia Residual','Family'],axis=1)

# Rename column name
happiness_2016_df = happiness_2016_df.rename(columns={'Country':'Country name', 'Happiness Rank': 'RANK', 'Happiness.Score':'Happiness score','Economy (GDP per Capita)':'GDP per capita','Trust (Government Corruption)':'Perceptions of corruption',
                                                      'Health (Life Expectancy)':'Healthy life expectancy','Happiness Score':'Happiness score'})

# === Year 2017 ===
# Drop columns
happiness_2017_df = happiness_2017_df.drop(['Whisker.high','Whisker.low','Dystopia.Residual','Family'],axis=1)

# Rename column name
happiness_2017_df = happiness_2017_df.rename(columns={'Country':'Country name','Happiness.Rank': 'RANK', 'Happiness.Score':'Happiness score','Economy..GDP.per.Capita.':'GDP per capita','Health..Life.Expectancy.':'Healthy life expectancy',
                                                      'Trust..Government.Corruption.':'Perceptions of corruption'})

# === Year 2018 ===
# Drop columns
happiness_2018_df = happiness_2018_df.drop(['Social support'],axis=1)

# Rename column name
happiness_2018_df = happiness_2018_df.rename(columns={'Overall rank': 'RANK', 'Country or region':'Country name','Score':'Happiness score','Freedom to make life choices':'Freedom'})

# === Year 2019 ===
# Drop columns
happiness_2019_df = happiness_2019_df.drop(['Social support'],axis=1)

# Rename column name
happiness_2019_df = happiness_2019_df.rename(columns={'Overall rank': 'RANK', 'Country or region':'Country name','Score':'Happiness score','Freedom to make life choices':'Freedom'})

# === Year 2020 ===
# Add rank
happiness_2020_df.insert(0, 'RANK',happiness_2020_df.index + 1)

# Drop columns
happiness_2020_df = happiness_2020_df.drop(['Regional indicator','Logged GDP per capita','upperwhisker','lowerwhisker','Healthy life expectancy','Standard error of ladder score','Freedom to make life choices','Dystopia + residual',
                                            'Explained by: Social support','Ladder score in Dystopia','Generosity','Perceptions of corruption','Social support'],axis=1)

# Rename column name
happiness_2020_df = happiness_2020_df.rename(columns={'Ladder score':'Happiness score','Explained by: Generosity':'Generosity','Explained by: Freedom to make life choices':'Freedom','Explained by: Perceptions of corruption':'Perceptions of corruption',
                                                      'Explained by: Log GDP per capita':'GDP per capita','Explained by: Healthy life expectancy':'Healthy life expectancy',})

# === Year 2021 ===
# Add rank 
#happiness_2021_df['RANK'] = happiness_2021_df.index + 1
happiness_2021_df.insert(0, 'RANK',happiness_2021_df.index + 1)

# Drop columns
happiness_2021_df = happiness_2021_df.drop(['Regional indicator','upperwhisker','lowerwhisker','Logged GDP per capita','Healthy life expectancy','Standard error of ladder score','Freedom to make life choices','Dystopia + residual',
                                            'Explained by: Social support','Ladder score in Dystopia','Generosity','Perceptions of corruption','Social support'],axis=1)

# Rename column name
happiness_2021_df = happiness_2021_df.rename(columns={'Country or region': 'Country name', 'Ladder score':'Happiness score', 'Explained by: Generosity':'Generosity','Explained by: Freedom to make life choices':'Freedom',
                                                      'Logged GDP per capita':'GDP per capita','Explained by: Perceptions of corruption':'Perceptions of corruption','Explained by: Log GDP per capita':'GDP per capita',
                                                      'Explained by: Healthy life expectancy':'Healthy life expectancy',})

# === Year 2022 ===
# Drop columns
happiness_2022_df = happiness_2022_df.drop(['Whisker-high','Whisker-low','Dystopia (1.83) + residual','Explained by: Social support'],axis=1)

# Rename column name
happiness_2022_df = happiness_2022_df.rename(columns={'Country': 'Country name', 'Explained by: Generosity':'Generosity','Explained by: Freedom to make life choices':'Freedom',
                                                      'Explained by: GDP per capita':'GDP per capita','Explained by: Perceptions of corruption':'Perceptions of corruption',
                                                      'Explained by: Healthy life expectancy':'Healthy life expectancy',})

# Check all dataframes after data cleaning
display(happiness_2015_df.head(2))
display(happiness_2016_df.head(2))
display(happiness_2017_df.head(2))
display(happiness_2018_df.head(2))
display(happiness_2019_df.head(2))
display(happiness_2020_df.head(2))
display(happiness_2021_df.head(2))
display(happiness_2022_df.head(2))

# Concatinate all dataframe
happiness_df = pd.concat([happiness_2015_df,happiness_2016_df,happiness_2017_df,happiness_2018_df,happiness_2019_df,happiness_2020_df,happiness_2021_df,happiness_2021_df], axis=0, ignore_index=True)

# Sort by Country name and year
happiness_df.sort_values(by=['Country name', 'year'], inplace=True)

# reset index
happiness_df.reset_index(drop=True, inplace=True)

# print the sorted dataframe
happiness_df.loc[:, ['Country name', 'Happiness score', 'year']]

"""# Choose Top 20 countries from the dataset
 Create a dataframe that has top 20 countries from the year 2015 to 2022.
 How: Calculate mean for each country and sort it out by descending order based on happiness score. This will be the dataset for the machine learning
"""

# Create dataframe to get mean for each country

# group by country and calculate mean of each column
grouped_df = happiness_df.groupby('Country name').mean()

# sort by country
grouped_df.sort_values(by='Happiness score', ascending=False, inplace=True)

# print the top 20 aggregated dataframe
top_20_countries_df = grouped_df.loc[:,['Happiness score']].head(20).reset_index()

# Show the dataframe
top_20_countries_df

# Make a list of top 20 countrie names

# extract the Country name column as a list
country_list = top_20_countries_df['Country name'].tolist()

# Create dataframe of top 20 countries based on average happiness score from 2015 to 2022
# create a boolean mask based on the Country name column
mask = happiness_df['Country name'].isin(country_list)

# filter the original dataframe using the boolean mask
filtered_df = happiness_df[mask]

# print the filtered dataframe
top_20_happycountries_df = filtered_df[['Country name','Happiness score','year']]

# Show the dataframe
top_20_happycountries_df.head(20)

"""# Data Modeling"""

# encode Country name column using one-hot encoding
onehot_df = pd.get_dummies(top_20_happycountries_df['Country name'])

# combine one-hot encoded features with the Happiness Score and year columns
features_df = pd.concat([onehot_df, top_20_happycountries_df['year'], top_20_happycountries_df['Happiness score']], axis=1)

# split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(features_df.drop(['Happiness score'], axis=1), features_df['Happiness score'], test_size=0.2, random_state=42) # (X, y, test_size, random_state)

# create XGBoost model and train on the training set
happy_xgb_model = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)
happy_xgb_model.fit(X_train, y_train)

# evaluate model on the testing set
y_pred = happy_xgb_model.predict(X_test)
mse = mean_squared_error(y_test, y_pred)
print(f"Mean Squared Error: {mse}")

features_df

"""# Prediction
This will take a range of years to predict top 20 countries
Prediction function parameter should take start and end year.
For example, if you want to know top 3 countries for next three years. This means you need to predict 2022, 2023 and 2024. Then return top 3 countries with mean of these three years. 
"""

# This function will interact with Lambda
def happy_prediction(start_year, end_year):

# create a new dataframe for the years 2022 to 2025
# new_years = pd.DataFrame({'year': [2022, 2023, 2024, 2025]})
  year_lists = list(range(start_year, end_year + 1))
  new_years = pd.DataFrame({'year': year_lists})

# create a cartesian product of the Country names and the new years
#  new_data = pd.MultiIndex.from_product([top_20_happycountries_df['Country name'].unique(), new_years['year']], names=['Country name', 'year']).to_frame(index=False)
  new_data = pd.MultiIndex.from_product([top_20_happycountries_df['Country name'].unique(), new_years['year']], names=['Country name', 'year']).to_frame(index=False)

# encode Country name column using one-hot encoding
  new_onehot_df = pd.get_dummies(new_data['Country name'])

# combine one-hot encoded features with the year column
  new_features_df = pd.concat([new_onehot_df, new_data['year']], axis=1)

# make predictions using the trained model
  new_data['Happiness score'] = happy_xgb_model.predict(new_features_df)

# print the predicted Happiness scores for the years 2022 to 2025 keichan
  new_happy_country_df = new_data.groupby('Country name').mean().sort_values(by='Happiness score', ascending=False).reset_index()

# Return the country dataframe
  return new_happy_country_df['Country name']

# create a new dataframe for the years 2022 to 2025
#new_years = pd.DataFrame({'year': [2022, 2023, 2024, 2025]})
#  year_lists = list(range(start_year, end_year + 1))
#  new_years = pd.DataFrame({'year': year_lists})

# create a cartesian product of the Country names and the new years
#  new_data = pd.MultiIndex.from_product([top_20_happycountries_df['Country name'].unique(), new_years['year']], names=['Country name', 'year']).to_frame(index=False)
#new_data = pd.MultiIndex.from_product([top_20_happycountries_df['Country name'].unique(), new_years['year']], names=['Country name', 'year']).to_frame(index=False)

# encode Country name column using one-hot encoding
#new_onehot_df = pd.get_dummies(new_data['Country name'])

# combine one-hot encoded features with the year column
#new_features_df = pd.concat([new_onehot_df, new_data['year']], axis=1)

# make predictions using the trained model
#new_data['Happiness score'] = happy_xgb_model.predict(new_features_df)

# print the predicted Happiness scores for the years 2022 to 2025 keichan
#new_happy_country_df = new_data.groupby('Country name').mean().sort_values(by='Happiness score', ascending=False).reset_index()

# Return the country dataframe
#new_happy_country_df['Country name']

"""# Save machine learning model
Save happy_model as an HDFf file.


"""

import pickle

# Set the file path for the first alternative model
file_path = "happy_model.pkl"

# Save your model to a file using pickle
with open(file_path, 'wb') as file:
    pickle.dump(happy_xgb_model, file)

# Download the model to your computer
files.download(file_path)

